# Thompson Sampling

- If you don't know what Multi-Armed Bandit Problem is and what Upper Confidence Bound (UCB) is then you should read it in this repo, in Upper Confidence Bound (UCB) section.

- UCB selected its actions based on the current **"averages"** of the rewards received from those actions.

- Thompson Sampling is an algorithm that uses exploration and exploitation to maximize the total rewards obtained from performing an action. 

- Thompson Sampling is also known as Posterior Sampling and Probability Matching.

- Exploration is when an action is repeated multiple times, and exploitation is when additional actions are performed with the goal of maximizing the reward based on the results of the previous actions, either rewards or penalties.

- In other words, new options are investigated in order to maximize rewards while exploiting previously investigated options.

### Algorithm:

<img src="TS0.png" width = "600px"/>

---

### If you like my work, you can contribute to https://www.patreon.com/xscotophilic

### Thank You!
